# ğŸ˜€ Emoji Detection System

A simple emoji/emotion detection pipeline that preprocesses facial images from the FER-2013 dataset, trains a classifier, and overlays predicted emojis on a live webcam feed.

## ğŸ“‹ Table of Contents

1. [ğŸš€ Overview](#-overview)
2. [âœ¨ Features](#-features)
3. [ğŸ› ï¸ Getting Started](#-getting-started)

   * [Prerequisites](#prerequisites)
   * [Installation](#installation)
4. [â–¶ï¸ Usage](#usage)

   * [Data Preparation](#data-preparation)
   * [Preprocessing](#preprocessing)
   * [Training](#training)
   * [Inference](#inference)
5. [ğŸ“ Project Structure](#-project-structure)
6. [âš™ï¸ Configuration](#-configuration)
7. [ğŸ¤ Contributing](#-contributing)
8. [ğŸ“„ License](#-license)
9. [ğŸ“« Contact](#-contact)

## ğŸš€ Overview

A quick description of your pipeline:

* **Input:** FER-2013 facial images or live webcam feed
* **Output:** Real-time emoji overlays matching detected emotions
* **Purpose:** Demonstrate facial emotion recognition with emoji visualization

## âœ¨ Features

* ğŸ” **Face detection & cropping** via OpenCV Haar cascades
* ğŸ–¼ï¸ **Bilateral filtering** for noise reduction
* ğŸ”„ **Resize & normalization** to 64Ã—64 grayscale images
* ğŸ·ï¸ **One-hot encoding** of emotion labels
* ğŸ“Š **Train/validation split** for hyperparameter tuning
* ğŸ¥ **Real-time emoji overlay** on live webcam feed

## ğŸ› ï¸ Getting Started

### Prerequisites

* Python 3.8+ installed
* OpenCV (`opencv-python`)
* NumPy, scikit-learn
* (Optional) Git LFS for large datasets

### Installation

```bash
git clone https://github.com/<YourUser>/Emoji-Detection-System.git
cd Emoji-Detection-System
pip install -r requirements.txt
```

## â–¶ï¸ Usage

### Data Preparation

1. Download and extract the `FER-2013_sampled` archive into the project root.
2. Ensure it contains two subfolders:

   * `train_balanced_7000/`
   * `test_balanced_7000/`

### Preprocessing

Run the Jupyter notebook or script to generate `.npy` files:

```bash
cd Notebooks
jupyter notebook preprocessing.ipynb
# or
python ../scripts/preprocess_data.py
```

### Training

Train the model (example using scikit-learn MLP):

```bash
python train.py --data-dir FER-2013_sampled --output-model models/emoji_mlp.pkl
```

### Inference

Launch the live webcam demo:

```bash
python inference.py --model models/emoji_mlp.pkl
```

## ğŸ“ Project Structure

```
Emoji-Detection-System/
â”œâ”€â”€ FER-2013_sampled/            # Sampled dataset splits
â”‚   â”œâ”€â”€ train_balanced_7000/     # Training images organized by emotion
â”‚   â””â”€â”€ test_balanced_7000/      # Test images organized by emotion
â”œâ”€â”€ Notebooks/                   # Jupyter notebooks
â”‚   â””â”€â”€ preprocessing.ipynb      # Data loading & preprocessing
â”œâ”€â”€ scripts/                     # Standalone scripts
â”‚   â””â”€â”€ preprocess_data.py
â”œâ”€â”€ models/                      # Saved model files
â”‚   â””â”€â”€ emoji_mlp.pkl
â”œâ”€â”€ templates/                   # Emoji PNG assets with transparency
â”œâ”€â”€ inference.py                 # Real-time emoji overlay script
â”œâ”€â”€ train.py                     # Training entrypoint
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # Project documentation
```

## âš™ï¸ Configuration

Optional flags or environment variables:

```bash
python train.py --epochs 30 --batch-size 64
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature-name`)
3. Commit your changes (`git commit -m "Add new feature"`)
4. Push to the branch (`git push origin feature-name`)
5. Open a Pull Request

## ğŸ“„ License

MIT Â© 2025 Your Name

## ğŸ“« Contact

Your Name â€” [your.email@example.com](mailto:your.email@example.com)
Project Link: [https://github.com/](https://github.com/)<YourUser>/Emoji-Detection-System
